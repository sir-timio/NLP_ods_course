{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span, Doc\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from utils import replace_ents_with_labels, \\\n",
    "                  replace_labels_with_ents, \\\n",
    "                  mark_ent_label_tokens, \\\n",
    "                  tokenize_df_with_spacy, \\\n",
    "                  visualize_ents, \\\n",
    "                  UNIQUE_LABELS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load generated texts and entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_load_path = Path(\"/archive/savkin/parsed_datasets/PII/generated_texts/rewriting/mixtral-8x7B-instruct-v0.1-GPTQ-rewrite-train-essays.json\")\n",
    "\n",
    "with open(texts_load_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    generated_texts_df = pd.DataFrame().from_records(data)\n",
    "generated_texts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/home/savkin/2024/PII_Data_Detection/pii/generated_datasets/faker_10k.csv\"\n",
    "\n",
    "generated_ents_df = pd.read_csv(load_path).drop(columns=\"COUNTRY\")\n",
    "generated_ents_combs_df = generated_ents_df.applymap(lambda x: [x]).agg(lambda row: row.to_dict(), axis=1).reset_index(drop=True)\n",
    "generated_ents_combs_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace entity-holders with new entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create true_ents_dict if absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PII_ENTS = [\n",
    "  (\"name\", \"NAME_STUDENT\", \"James Brown\"), # обрати внимание ФИО это одна сущность или несколько !!!!\n",
    "  (\"email\", \"EMAIL\", \"example@email.com\"),\n",
    "  (\"personal_url\", \"URL_PERSONAL\", \"https://example.com\"),\n",
    "  (\"username\", \"USERNAME\", \"john42\"),\n",
    "  (\"address\", \"STREET_ADDRESS\", \"221B, Baker Street, London\"),\n",
    "  (\"phone_num\", \"PHONE_NUM\", \"+1 212 555 0188\"),\n",
    "  (\"userid\", \"ID_NUM\", \"123456789\")\n",
    "]\n",
    "\n",
    "LABEL2ENT = {l: e for _, l, e in PII_ENTS}\n",
    "\n",
    "def add_label_dict(row):\n",
    "    row[\"true_ents_dict\"] = {label: [LABEL2ENT[label]] for label in UNIQUE_LABELS if row[label] is not None}\n",
    "    return row\n",
    "\n",
    "generated_texts_df = generated_texts_df.agg(add_label_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select random fake data-rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_ent_combs = len(generated_ents_combs_df)\n",
    "n_ent_combs = len(generated_texts_df)\n",
    "\n",
    "rand_comb_indexes = np.random.randint(n_unique_ent_combs, size=n_ent_combs)\n",
    "\n",
    "generated_texts_df[\"label2ent\"] = pd.Series(generated_ents_combs_df.to_numpy()[rand_comb_indexes])\n",
    "generated_texts_df[\"label2ent\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace labels with ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label2position' in generated_texts_df.columns:\n",
    "    generated_texts_df = generated_texts_df.agg(replace_labels_with_ents, axis=1)\n",
    "else:\n",
    "    generated_texts_df = generated_texts_df.agg(replace_ents_with_labels, axis=1) \\\n",
    "                                           .agg(tokenize_df_with_spacy, axis=1) \\\n",
    "                                           .agg(mark_ent_label_tokens, axis=1) \\\n",
    "                                           .agg(replace_labels_with_ents, axis=1)\n",
    "\n",
    "generated_texts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = generated_texts_df.iloc[3]\n",
    "html = visualize_ents(row[\"tokens\"], row[\"trailing_whitespace\"], row[\"labels\"])\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"{texts_load_path.name}_\" \n",
    "generated_texts_df.to_records(,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
